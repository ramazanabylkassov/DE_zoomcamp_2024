{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3603643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession, types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f88944a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/02 09:32:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('pyspark_test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8770fc41",
   "metadata": {},
   "source": [
    "# Question 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d40ef301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "079cd369",
   "metadata": {},
   "outputs": [],
   "source": [
    "fhvh_schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True), \n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True), \n",
    "    types.StructField('dropOff_datetime', types.TimestampType(), True), \n",
    "    types.StructField('PUlocationID', types.IntegerType(), True), \n",
    "    types.StructField('DOlocationID', types.IntegerType(), True), \n",
    "    types.StructField('SR_Flag', types.StringType(), True), \n",
    "    types.StructField('Affiliated_base_number', types.IntegerType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f3ed099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhvh = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(fhvh_schema) \\\n",
    "    .csv('../data/raw/fhvh/fhv_tripdata_2019-10.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c0b75df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " dispatching_base_num   | B00009              \n",
      " pickup_datetime        | 2019-10-01 00:23:00 \n",
      " dropOff_datetime       | 2019-10-01 00:35:00 \n",
      " PUlocationID           | 264                 \n",
      " DOlocationID           | 264                 \n",
      " SR_Flag                | null                \n",
      " Affiliated_base_number | null                \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fhvh.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b271e742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fhvh.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd0a72cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_fhvh \\\n",
    "    .repartition(6) \\\n",
    "    .write \\\n",
    "    .parquet('../data/pq/fhvh/2019/10/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c3410cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = spark \\\n",
    "    .read.parquet('../data/pq/fhvh/2019/10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9557b349",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_parquet.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd8d9ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " dispatching_base_num   | B03162              \n",
      " pickup_datetime        | 2019-10-02 11:53:57 \n",
      " dropOff_datetime       | 2019-10-02 12:14:40 \n",
      " PUlocationID           | 192                 \n",
      " DOlocationID           | 16                  \n",
      " SR_Flag                | null                \n",
      " Affiliated_base_number | null                \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_parquet.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa513b6",
   "metadata": {},
   "source": [
    "# Question 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b60989d",
   "metadata": {},
   "source": [
    "Average size of the Parquet file = 6 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36ad6a79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramazan/spark/spark-3.4.2-bin-hadoop3/python/pyspark/sql/dataframe.py:330: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_parquet.registerTempTable('fhvh_2019_10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e15d6b",
   "metadata": {},
   "source": [
    "# Question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5d93f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:=============================>                            (3 + 3) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|amount|\n",
      "+------+\n",
      "| 62610|\n",
      "+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT COUNT(date_trunc(\"day\", pickup_datetime)) AS amount\n",
    "    FROM fhvh_2019_10\n",
    "    WHERE date_trunc(\"day\", pickup_datetime) = '2019-10-15'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0a16c6",
   "metadata": {},
   "source": [
    "# Question 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62f2f39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|max_duration|\n",
      "+------------+\n",
      "|    631152.5|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unix_timestamp = converts date to seconds\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT MAX((unix_timestamp(dropoff_datetime) - unix_timestamp(pickup_datetime))/3600) AS max_duration\n",
    "    FROM fhvh_2019_10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382ca7a4",
   "metadata": {},
   "source": [
    "# Question 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8634c303",
   "metadata": {},
   "source": [
    "Local port for Spark UI: 4040"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e644bb",
   "metadata": {},
   "source": [
    "# Question 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ea2a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.parquet('../data/pq/zones/part-00000-0ad78abf-3482-4c49-874c-4494d4c8105d-c000.snappy.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17d9a98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------\n",
      " LocationID   | 1              \n",
      " Borough      | EWR            \n",
      " Zone         | Newark Airport \n",
      " service_zone | EWR            \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8153c1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramazan/spark/spark-3.4.2-bin-hadoop3/python/pyspark/sql/dataframe.py:330: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_zones.registerTempTable(\"zones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "77b98c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+\n",
      "|zone_with_least_frequent_pick_ups|\n",
      "+---------------------------------+\n",
      "|                      Jamaica Bay|\n",
      "+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    SELECT t2.Zone as zone_with_least_frequent_pick_ups\n",
    "    FROM fhvh_2019_10 t1 \n",
    "    LEFT JOIN zones t2 ON t1.PUlocationID = t2.LocationID\n",
    "    WHERE t1.PUlocationID = (\n",
    "        SELECT PUlocationID\n",
    "        FROM fhvh_2019_10\n",
    "        WHERE PUlocationID IS NOT NULL\n",
    "        GROUP BY PUlocationID\n",
    "        ORDER BY COUNT(*) ASC\n",
    "        LIMIT 1\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "spark.sql(sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "97ef4b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|PUlocationID|amount|\n",
      "+------------+------+\n",
      "|           2|     1|\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT PUlocationID, COUNT(*) AS amount\n",
    "    FROM fhvh_2019_10\n",
    "    WHERE PUlocationID IS NOT NULL\n",
    "    GROUP BY PUlocationID\n",
    "    ORDER BY COUNT(*) ASC\n",
    "    LIMIT 1\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45076049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
