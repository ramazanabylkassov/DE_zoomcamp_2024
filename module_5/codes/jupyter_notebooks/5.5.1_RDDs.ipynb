{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d0780ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/01 04:37:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('pyspark_test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90fb37bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet('../../data/pq/green/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04ced144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- trip_type: integer (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f00719d",
   "metadata": {},
   "source": [
    "SELECT \n",
    "    date_trunc('hour', lpep_pickup_datetime) AS hour, \n",
    "    PULocationID AS zone,\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "FROM green\n",
    "WHERE lpep_pickup_datetime > \"2020-01-01 00:00:00\"\n",
    "GROUP BY hour, zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c207818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = df_green \\\n",
    "    .select('lpep_pickup_datetime', 'PULocationID', 'total_amount') \\\n",
    "    .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cca00b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 13, 10, 15), PULocationID=74, total_amount=44.97),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 20, 15, 9), PULocationID=67, total_amount=33.45),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 15, 20, 23, 41), PULocationID=260, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 5, 16, 32, 26), PULocationID=82, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 29, 19, 22, 42), PULocationID=166, total_amount=12.74)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1075e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 13, 10, 15), PULocationID=74, total_amount=44.97),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 20, 15, 9), PULocationID=67, total_amount=33.45),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 15, 20, 23, 41), PULocationID=260, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 5, 16, 32, 26), PULocationID=82, total_amount=8.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 29, 19, 22, 42), PULocationID=166, total_amount=12.74)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implement WHERE lpep_pickup_datetime > \"2020-01-01 00:00:00\" filter\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start = datetime(year=2020, month=1, day=1)\n",
    "\n",
    "# rdd.filter(lambda row: row.lpep_pickup_datetime >= start).take(5)\n",
    "\n",
    "def filter_outliers(row):\n",
    "    return row.lpep_pickup_datetime >= start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "541d6ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement \"GROUP BY hour, zone\" \n",
    "\n",
    "def prepare_for_grouping(row):\n",
    "    hour = row.lpep_pickup_datetime.replace(minute=0, second=0, microsecond=0)\n",
    "    zone = row.PULocationID\n",
    "    key = (hour, zone)\n",
    "    \n",
    "    amount = row.total_amount\n",
    "    count = 1\n",
    "    value = (amount, count)\n",
    "    \n",
    "    return (key, value)\n",
    "\n",
    "def calculate_revenue(left, right):\n",
    "    left_amount, left_count = left\n",
    "    right_amount, right_count = right\n",
    "    \n",
    "    output_amount = left_amount + right_amount\n",
    "    output_count = left_count + right_count\n",
    "    \n",
    "    return(output_amount, output_count)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c33c1362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnest the tuple into separate cells with column names\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "RevenueRow = namedtuple('RevenueRow', ['hour', 'zone', 'revenue', 'count'])\n",
    "\n",
    "def unwrap(row):\n",
    "    return RevenueRow(\n",
    "        hour=row[0][0], \n",
    "        zone=row[0][1], \n",
    "        revenue=row[1][0], \n",
    "        count=row[1][1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "574a7722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "\n",
    "rdd_schema = types.StructType([\n",
    "    types.StructField('hour', types.TimestampType(), True), \n",
    "    types.StructField('zone', types.IntegerType(), True), \n",
    "    types.StructField('revenue', types.DoubleType(), True), \n",
    "    types.StructField('count', types.IntegerType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08e671d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = rdd \\\n",
    "    .filter(filter_outliers) \\ # WHERE lpep_pickup_datetime > \"2020-01-01 00:00:00\"\n",
    "    .map(prepare_for_grouping) \\ # GROUP BY hour, zone\n",
    "    .reduceByKey(calculate_revenue) \\ # GROUP BY hour, zone\n",
    "    .map(unwrap) \\ # unnest the key & value pairs AND give column names\n",
    "    .toDF(rdd_schema) # convert to a spark DF with specified schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e588d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hour: timestamp (nullable = true)\n",
      " |-- zone: integer (nullable = true)\n",
      " |-- revenue: double (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82aa00eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.write.parquet('../../data/pq/tmp/green_revenue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cc0c01",
   "metadata": {},
   "source": [
    "## [MapPartition](https://www.youtube.com/watch?v=k3uB2K99roI&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52e4ac9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- trip_type: integer (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7f7860b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['VendorID', 'lpep_pickup_datetime', 'PULocationID', 'DOLocationID', 'trip_distance']\n",
    "duration_rdd = df_green \\\n",
    "    .select(columns) \\\n",
    "    .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bc73c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(df):\n",
    "    y_pred = df.trip_distance * 5\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d8bd7282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rows = duration_rdd\n",
    "\n",
    "def apply_model_in_batch(rows):\n",
    "    df_pandas = pd.DataFrame(rows, columns=columns)\n",
    "    predictions = model_predict(df_pandas)\n",
    "    df_pandas['predicted_duration'] = predictions\n",
    "    \n",
    "    for row in df_pandas.itertuples(): # use itertuples() function to a dataframe to turn it to a generator\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "240bc95a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_predicts = duration_rdd \\\n",
    "    .mapPartitions(apply_model_in_batch) \\\n",
    "    .toDF() \\\n",
    "    .drop('Index')\n",
    "\n",
    "# the result shows a significant uneven distribution of rows among partitions.\n",
    "# Repartition can be used to even out the amount of rows, but this is going to be resource expensive operation\n",
    "# OR \n",
    "# You can use itertools in python to yield certain amount of rows from the partition in order to not overwhelm the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5c435df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 45:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|predicted_duration|\n",
      "+------------------+\n",
      "|63.849999999999994|\n",
      "|              40.0|\n",
      "|              6.35|\n",
      "|              6.25|\n",
      "| 9.200000000000001|\n",
      "|               3.8|\n",
      "|16.599999999999998|\n",
      "|             11.05|\n",
      "|               4.5|\n",
      "|              30.5|\n",
      "|               8.7|\n",
      "|5.8999999999999995|\n",
      "|              11.0|\n",
      "|              15.2|\n",
      "|              4.25|\n",
      "|25.299999999999997|\n",
      "|7.8500000000000005|\n",
      "|              34.0|\n",
      "| 5.300000000000001|\n",
      "|              6.15|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_predicts.select('predicted_duration').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ab76d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
